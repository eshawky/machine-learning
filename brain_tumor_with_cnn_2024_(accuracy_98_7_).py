# -*- coding: utf-8 -*-
"""Brain Tumor with CNN 2024 (accuracy 98.7%).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18x7Wab2piuqGYnjhDB2ISV8PFEcloi57

# Importing Necessary Libraries
"""

import os
import cv2
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report

from tensorflow.keras.models import Sequential, save_model, Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.applications import VGG16, ResNet50
from tensorflow.keras.preprocessing.image import ImageDataGenerator

"""# (1) Loading The Dataset"""

def load_dataset(dataset_path, img_size):
    images = []
    labels = []

    for label_folder in os.listdir(dataset_path):
        label_path = os.path.join(dataset_path, label_folder)

        for image_file in os.listdir(label_path):
            image_path = os.path.join(label_path, image_file)

            img = cv2.imread(image_path)

            img = cv2.resize(img, img_size)

            images.append(img)
            labels.append(label_folder)

    return np.array(images), np.array(labels)

"""# (2) Label Encoding"""

def label_encoding(data_labels):
    # ('glioma': 0 / 'meningioma': 1 / 'notumor': 2 / 'pituitary': 3)
    general_labels = ['glioma', 'meningioma', 'notumor', 'pituitary']

    new_data_labels = []
    for label in data_labels:
        new_data_labels.append(general_labels.index(label))

    return np.array(new_data_labels)

"""# (3) Data Augmentation"""

def plot_augmented_samples(X_train, train_datagen, seed=None):

    def plot_images(images, titles, ncols=6, figsize=(15, 15)):
        fig, ax = plt.subplots(nrows=1, ncols=ncols, figsize=figsize)
        for i, (img, title) in enumerate(zip(images, titles)):
            ax[i].imshow(img)
            ax[i].set_title(title)
            ax[i].axis('off')
        plt.show()

    if seed != None:
        np.random.seed(seed)

    sample_indices = np.random.choice(len(X_train), 3, replace=False)
    samples = X_train[sample_indices]

    for sample in samples:
        images = [sample]  # Start with the original image
        titles = ['Original']

        generator = train_datagen.flow(sample.reshape((1,) + sample.shape), batch_size=1)

        # Generate 5 augmented images
        for i in range(5):
            augmented_image = next(generator)[0]
            if augmented_image.dtype in ['float32', 'float64']:
                augmented_image = (augmented_image * 255).astype('uint8')
            images.append(augmented_image)
            titles.append(f'Augmented {i+1}')

        plot_images(images, titles)

def make_generators(X_train, X_val, X_test, encoded_y_train, encoded_y_val, encoded_y_test, batch_size, augment=False):
    if augment:
        train_datagen = ImageDataGenerator(
                                            rescale=1./255,
                                            rotation_range=10,
                                            width_shift_range=0.1,
                                            height_shift_range=0.1,
                                            shear_range=0.2,
                                            zoom_range=0.1,
                                            horizontal_flip=True,
                                            fill_mode='nearest'
                                          )
    else:
        train_datagen = ImageDataGenerator(rescale=1./255)

    # For validation and test data, you typically only rescale
    val_datagen  = ImageDataGenerator(rescale=1./255)
    test_datagen = ImageDataGenerator(rescale=1./255)

    if augment:
        plot_augmented_samples(X_train, train_datagen)

    train_generator = train_datagen.flow(X_train, encoded_y_train, batch_size=batch_size, shuffle=True, seed=101)

    val_generator = val_datagen.flow(X_val, encoded_y_val, batch_size=batch_size, shuffle=False)

    test_generator = test_datagen.flow(X_test, encoded_y_test, batch_size=batch_size, shuffle=False)

    return train_generator, val_generator, test_generator

"""# (4) Model Architectures"""

def create_basic_cnn(input_shape, filters, kernel_size, pool_size, dropout_rate, n_hidden):
    model = Sequential()
    model.add(Conv2D(filters=filters[0], kernel_size=kernel_size, activation='relu', input_shape=input_shape, padding='same'))
    model.add(MaxPooling2D(pool_size=pool_size))

    for f in filters[1:]:
        model.add(Conv2D(filters=f, kernel_size=kernel_size, activation='relu', padding='same'))
        model.add(MaxPooling2D(pool_size=pool_size))

    model.add(Flatten())

    for n in n_hidden:
        model.add(Dense(units=n, activation='relu'))
        model.add(Dropout(dropout_rate))

    model.add(Dense(units=4, activation='softmax'))

    print(model.summary())
    return model

def get_model(model_type, params):
    if model_type == 'basic_cnn':
        return create_basic_cnn(
            input_shape=params['input_shape'],
            filters=params['filters'],
            kernel_size=params['kernel_size'],
            pool_size=params['pool_size'],
            dropout_rate=params['dropout_rate'],
            n_hidden=params['n_hidden']
        )
    else:
        raise ValueError(f"Unknown model type: {model_type}")

"""# (5) Model Evaluation"""

def plot_results(history):
    plt.figure(figsize=(12, 5))

    # Plot loss
    plt.subplot(1, 2, 1)
    plt.plot(history.history['loss'], label='train_loss')
    plt.plot(history.history['val_loss'], label='val_loss')
    plt.legend()
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.title('Loss over Epochs')

    # Plot accuracy
    plt.subplot(1, 2, 2)
    plt.plot(history.history['accuracy'], label='train_accuracy')
    plt.plot(history.history['val_accuracy'], label='val_accuracy')
    plt.legend()
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.title('Accuracy over Epochs')

    plt.tight_layout()
    plt.show()

def plot_confusion_matrix(model, test_generator, encoded_y_test):
    predictions = model.predict(test_generator)
    predicted_classes = [np.argmax(pred) for pred in predictions]

    conf_matrix = confusion_matrix(encoded_y_test, predicted_classes)

    plt.figure(figsize=(8, 6))
    plt.imshow(conf_matrix, cmap='Blues', interpolation='nearest')
    plt.title('Confusion Matrix')
    plt.colorbar()

    classes = ['glioma', 'meningioma', 'notumor', 'pituitary']

    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)
    for i in range(len(classes)):
        for j in range(len(classes)):
            plt.text(i, j, str(conf_matrix[i, j]), ha='center', va='center')

    plt.xlabel('True Labels')
    plt.ylabel('Predicted Labels')
    plt.show()

def plot_classification_report(model, test_generator, encoded_y_test):
    predictions = model.predict(test_generator)
    predicted_classes = [np.argmax(pred) for pred in predictions]

    classes = ['glioma', 'meningioma', 'notumor', 'pituitary']

    report = classification_report(encoded_y_test, predicted_classes, target_names=classes, output_dict=True)

    metrics = {label: report[label] for label in classes if label in report}

    precision = [metrics[label]['precision'] for label in classes]
    recall = [metrics[label]['recall'] for label in classes]
    f1_score = [metrics[label]['f1-score'] for label in classes]

    data = {
        'Precision': precision,
        'Recall': recall,
        'F1-Score': f1_score
    }

    df = pd.DataFrame(data, index=classes)

    plt.figure(figsize=(10, 6))
    sns.heatmap(df, annot=True, cmap='Blues', fmt=".2f", linewidths=0.5)
    plt.title('Classification Report')
    plt.xlabel('Metrics')
    plt.ylabel('Classes')
    plt.show()

def evaluate_model(model, test_generator):
    evaluation = model.evaluate(test_generator)
    test_loss = evaluation[0]
    test_accuracy = evaluation[1]

    return test_loss, test_accuracy

"""# (6) Experiment Execution"""

def run_experiment(params, X_train, X_val, X_test, encoded_y_train, encoded_y_val, encoded_y_test):
    model = get_model(params['model_type'], params)

    model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])

    train_gen, val_gen, test_gen = make_generators(
        X_train, X_val, X_test,
        encoded_y_train, encoded_y_val, encoded_y_test,
        batch_size=params['batch_size'],
        augment=params['augment']
    )

    history = model.fit(train_gen, validation_data=val_gen, epochs=params['epochs'], verbose=1)
    plot_results(history)

    plot_confusion_matrix(model, test_gen, encoded_y_test)

    plot_classification_report(model, test_gen, encoded_y_test)

    loss, accuracy = evaluate_model(model=model, test_generator=test_gen)

    result = {
        'Model': model,
        'Model Type': params['model_type'],
        'With Augmentation': 'Yes' if params['augment'] else 'No',
        'Input Shape': params['input_shape'],
        'Epochs': params['epochs'],
        'Batch Size': params['batch_size'],
        'Test Loss': loss,
        'Test Accuracy': accuracy
    }

    return result

"""# (7) Best Model Save"""

def save_best_model(results, save_path='../saved_models/best_classification_model.h5'):
    best_model = None
    best_accuracy = 0

    for result in results:
        if result['accuracy'] > best_accuracy:
            best_accuracy = result['accuracy']
            best_model = result['model']

    if best_model:
        save_model(best_model, save_path)
        print(f"Best model saved to {save_path}")
    else:
        print("No best model found to save.")

"""# Main Execution"""

experiments = [
    {
        'model_type': 'basic_cnn',
        'dropout_rate': 0.5,
        'filters': [32, 64, 128, 256, 512],
        'input_shape': (224, 224, 3),
        'epochs': 60,
        'batch_size': 32,
        'kernel_size': (3, 3),
        'pool_size': (2, 2),
        'n_hidden': [512],
        'augment': True,
        'image_size': (224, 224)
    }
]

#brain_dataset_training_path = '../BT_Dataset/Training'
#brain_dataset_testing_path = '../BT_Dataset/Testing'

#brain_dataset_training_path = '/kaggle/input/brain-tumor-mri-dataset/Training'
#brain_dataset_testing_path = '/kaggle/input/brain-tumor-mri-dataset/Testing'

#brain_dataset_training_path = 'https://www.kaggle.com/datasets/masoudnickparvar/brain-tumor-mri-dataset/Training'
#brain_dataset_testing_path = 'https://www.kaggle.com/datasets/masoudnickparvar/brain-tumor-mri-dataset/Testing'

brain_dataset_training_path = '/kaggle/input/brain-tumor-mri-dataset/Training'
brain_dataset_testing_path = '/kaggle/input/brain-tumor-mri-dataset/Testing'

from google.colab import drive
drive.mount('/content/drive')

basic_cnn_experiments = []

for params in experiments:
    print(f"Running experiment with parameters: {params}")

    X_train, y_train = load_dataset(brain_dataset_training_path, params['image_size'])
    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=101)
    X_test, y_test = load_dataset(brain_dataset_testing_path, params['image_size'])

    encoded_y_train = label_encoding(y_train)
    encoded_y_val = label_encoding(y_val)
    encoded_y_test = label_encoding(y_test)

    print(f'Train images shape is : {X_train.shape}')
    print(f'Train labels shape is : {encoded_y_train.shape}')

    print(f'Validation images shape is : {X_val.shape}')
    print(f'Validation labels shape is : {encoded_y_val.shape}')

    print(f'Test images shape is : {X_test.shape}')
    print(f'Test labels shape is : {encoded_y_test.shape}')

    result = run_experiment(params, X_train, X_val, X_test, encoded_y_train, encoded_y_val, encoded_y_test)

    save_model(result['Model'], f"../saved_models/{params['model_type']}_high_epochs", save_format='h5')

    basic_cnn_experiments.append(result)

high_epochs_experiments = pd.DataFrame(basic_cnn_experiments)
high_epochs_experiments.to_csv('../saved_models/basic_cnn_high_epochs_experiment.csv', index=False)
high_epochs_experiments